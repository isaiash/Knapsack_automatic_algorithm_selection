{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'outputs/'\n",
    "FEATURES_PATH = 'features/'\n",
    "ALGORITHMS = ['dp1', 'dp2', 'greedy', 'bf', 'bnb', 'cplex']\n",
    "LEVELS = [1,2,3,4,5,6,7,8]\n",
    "LEVELS_SIZE = [19198 ,9983, 6664, 4994, 3999, 3333, 2857, 2500]\n",
    "FEATURES = ['num_elem',\n",
    "            'cap',\n",
    "            'cap_mean_w',\n",
    "            'cap_median_w', \n",
    "            'cap_desv_w', \n",
    "            'mean_w_mean_v',\n",
    "            'median_w_median_v', \n",
    "            'desv_w_desv_v',\n",
    "            'max_w_min_w',\n",
    "            'max_v_min_v',\n",
    "            'mean_w',\n",
    "            'median_w', \n",
    "            'desv_w', \n",
    "            'min_w', \n",
    "            'max_w', \n",
    "            'mean_v', \n",
    "            'median_v', \n",
    "            'desv_v', \n",
    "            'min_v', \n",
    "            'max_v',\n",
    "            'p_coef' \n",
    "           ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(lvl, id_):\n",
    "    return np.array(open(FEATURES_PATH +str(lvl)+'/'+ str(id_),'r').read().split(), dtype=float)\n",
    "\n",
    "def get_best(lvl, id_, t):\n",
    "    best_fo = 0\n",
    "    best_alg = 0\n",
    "    best_time = 1000000\n",
    "    for alg in ALGORITHMS:\n",
    "        if lvl not in list(alg_data[alg].keys()): continue\n",
    "        for res in alg_data[alg][lvl][id_]:\n",
    "            if res[1] < t and res[0] >= best_fo:\n",
    "                if res[1] < best_time:\n",
    "                    best_alg = ALGORITHMS.index(alg)+1\n",
    "                    best_time = res[1]\n",
    "    return best_alg\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(7), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1]) \n",
    "    plt.xticks(np.arange(7), ('NO', *ALGORITHMS))\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_files = os.listdir(OUTPUT_PATH)\n",
    "alg_data = defaultdict(list)\n",
    "\n",
    "print(\"Faltan los siguientes resultados:\")\n",
    "for alg in ALGORITHMS:\n",
    "    alg_data[alg] = defaultdict(list)\n",
    "    for lvl in LEVELS:\n",
    "        filename = alg + \"_\" + str(lvl)\n",
    "        if filename not in output_files: # En caso de que todavÃ­a no hayan resultados\n",
    "            print(alg, lvl)\n",
    "            continue\n",
    "        alg_data[alg][lvl] = defaultdict(list)\n",
    "        file = open(OUTPUT_PATH+filename,'r')\n",
    "        for row in file:\n",
    "            id_, fo, time = row.split()\n",
    "            alg_data[alg][lvl][int(id_)].append([(float)(fo), (float)(time)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = np.logspace(1, 30, num=100, base=1.1)-1.1 # escala logaritmica para los tiempos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for lvl in LEVELS:\n",
    "    print(\"level \"+str(lvl)+\"...\")\n",
    "    for id_ in range(LEVELS_SIZE[lvl-1]):\n",
    "        fts = get_features(lvl, id_)\n",
    "        for t in timesteps:\n",
    "            train_data.append([*fts, t+1])\n",
    "            train_label.append(get_best(lvl, id_, t))\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing al ojo\n",
    "lvl_ = 1\n",
    "id_ = 100\n",
    "for alg in ALGORITHMS:\n",
    "    print(alg, alg_data[alg][lvl_][id_])\n",
    "    \n",
    "print('BEST: ',ALGORITHMS[get_best(lvl_,id_,1)-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data=train_data, columns=[*FEATURES, 't'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras# Tensor \n",
    "import tensorflow as tf\n",
    "#from tensorflow import keras\n",
    "#from keras.layers import Dropout, Dense\n",
    "from keras import Sequential\n",
    "from keras import optimizers\n",
    "from keras.models import Model   \n",
    "from keras.layers import *\n",
    "import keras\n",
    "# Helper libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_train.csv', 'w') as FOUT:\n",
    "    np.savetxt(FOUT, X_train)\n",
    "with open('X_test.csv', 'w') as FOUT:\n",
    "    np.savetxt(FOUT, X_test)\n",
    "with open('y_train.csv', 'w') as FOUT:\n",
    "    np.savetxt(FOUT, y_train)\n",
    "with open('y_test.csv', 'w') as FOUT:\n",
    "    np.savetxt(FOUT, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.loadtxt('y_train.csv', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.loadtxt('X_train.csv', dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(128, input_shape = (22,), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5), \n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5), \n",
    "    Dense(7, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(np.array(X_train), \n",
    "                    np.array(y_train), \n",
    "                    epochs=10, \n",
    "                    validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0, n_jobs=-1 ,verbose=1)\n",
    "h = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clfsvm = svm.LinearSVC()\n",
    "clfsvm.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfsvm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Accuracy (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.loadtxt('X_test.csv', dtype=float)\n",
    "y_test = np.loadtxt('y_test.csv', dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rojo predicho\n",
    "# azul verdadero\n",
    "i = 5\n",
    "print(X_test[i])\n",
    "print(pred[:10])\n",
    "print(y_test[:10])\n",
    "plt.figure()\n",
    "plot_value_array(i, pred,  np.array(y_test, dtype=int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_predictions = np.argmax(predictions,axis=1)\n",
    "\n",
    "cm = sklearn.metrics.confusion_matrix(np.array(y_test, dtype=int), pred)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.matshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array(X_test[0])\n",
    "sample = (np.expand_dims(sample,0))\n",
    "predictions_single = model.predict(sample)\n",
    "\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
